{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7473024-4336-4128-8968-1da0b1fecbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import survLime\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sklearn\n",
    "\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis, RandomSurvivalForest\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import integrated_brier_score\n",
    "from sksurv.svm import FastSurvivalSVM\n",
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from pycox.models import LogisticHazard\n",
    "from pycox.evaluation import EvalSurv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "from derma.general.preprocessing.transformers import (TransformToNumeric, \n",
    "                                                      TransformToDatetime, \n",
    "                                                      ComputeAge,\n",
    "                                                      TransformToObject,\n",
    "                                                      KeepColumns,\n",
    "                                                      ComputeAJCC,\n",
    "                                                      LinkTumourPartToParent,\n",
    "                                                      TransformCbRegression,\n",
    "                                                      ConvertCategoriesToNaN,\n",
    "                                                      ExponentialTransformer,\n",
    "                                                      RenameLabValues,\n",
    "                                                      CustomScaler,\n",
    "                                                      CustomImputer)\n",
    "\n",
    "from derma.general.ingestion.data_loader_csv import SurvivalLoader\n",
    "import config_os as settings_file\n",
    "from derma.general.preprocessing.encoders import (OrdinalEncoder,\n",
    "                                                  GenderEncoder,\n",
    "                                                  AbsentPresentEncoder,\n",
    "                                                   LABEncoder,\n",
    "                                                  CategoricalEncoder)\n",
    "from derma.general.ingestion.data_loader_csv import SurvivalLoader\n",
    "#from utils.script_utils import (obtain_pipeline, data_preprocessing,\n",
    "#                            obtain_datasets, obtain_loaders,\n",
    "#                            obtain_splits, Concordance, obtain_wsi_ids)\n",
    "\n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "# code you want to evaluate\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "np.random.seed(123456)\n",
    "\n",
    "get_target = lambda df: df[['event','duration']]\n",
    "path = '/home/carlos.hernandez/datasets/csvs/data-surv_20220302.csv'\n",
    "\n",
    "\n",
    "clinical_columns = ['patient_gender', 'cutaneous_biopsy_breslow', 'age']\n",
    "\n",
    "X, _, time, event  = SurvivalLoader('os').load_data(path)\n",
    "time = [int(x) for x in time]\n",
    "X['duration'] = time\n",
    "\n",
    "X['event']    = event\n",
    "X.dropna(subset=['duration'],inplace=True)\n",
    "X = X[X['duration']>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d16fb5c-f36e-41ce-a8f7-daa1f41b2c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-Index : 0.7814756229346447 +- 0.0\n",
      "I - Brier-score : 0.17157551408462574 +- 0.0\n"
     ]
    }
   ],
   "source": [
    "total_c_index  = []\n",
    "total_ib_score = []\n",
    "\n",
    "keep_cols = clinical_columns\n",
    "settings_file.keep_cols = {'cols' : keep_cols}\n",
    "pipe = sklearn.pipeline.Pipeline(steps=[\n",
    "    ('TransformToNumeric', TransformToNumeric(**settings_file.transform_to_numeric)), \n",
    "    ('TransformToDatetime', TransformToDatetime(**settings_file.transform_to_datetime)),\n",
    "    ('TransformToObject', TransformToObject(**settings_file.transform_to_object)),\n",
    "    ('ComputeAge', ComputeAge(**settings_file.compute_age)),\n",
    "    ('tr_tm', LinkTumourPartToParent(**settings_file.link_tumour_part_to_parent)),\n",
    "    ('tr_cb', TransformCbRegression(**settings_file.transform_cb_regression)),\n",
    "    ('tr0', ConvertCategoriesToNaN(**settings_file.convert_categories_to_nan)),\n",
    "    ('tr2', GenderEncoder(**settings_file.gender_encoder)),\n",
    "    ('tr3', AbsentPresentEncoder(**settings_file.absent_present_encoder)),\n",
    "    (\"tr4\", CategoricalEncoder(**settings_file.categorical_encoder)),\n",
    "    ('tr7', LABEncoder(**settings_file.lab_encoder)),\n",
    "    ('OrdinalEncoder', OrdinalEncoder(**settings_file.ordinal_encoder)),\n",
    "    ('ComputeAJCC', ComputeAJCC(**settings_file.compute_ajcc)),\n",
    "    ('tr5', ExponentialTransformer(**settings_file.exponential_transformer)),\n",
    "    ('RenameLabValues', RenameLabValues(**settings_file.rename_lab_values)),\n",
    "\n",
    "    ('KeepColumns', KeepColumns(**settings_file.keep_cols)),\n",
    "    ('CustomImputer', CustomImputer(strategy='mean')),\n",
    "    #('CustomScaler', CustomScaler()),\n",
    "    #('GBSA', GradientBoostingSurvivalAnalysis(loss='coxph'))\n",
    "    #('CPH', CoxPHSurvivalAnalysis())\n",
    "    #  ('model', FastSurvivalSVM(random_state=42))\n",
    "    ('xgb', RandomSurvivalForest(random_state=42))\n",
    "    ])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.copy(), np.zeros(len(X)), test_size=0.2, random_state=1)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test.copy(), np.zeros(len(X_test)), test_size=0.5, random_state=1)\n",
    "\n",
    "\n",
    "y_train_list = get_target(X_train)\n",
    "# y_val   = get_target(X_val)\n",
    "y_test  = get_target(X_test)\n",
    "\n",
    "y_train_list = Surv.from_dataframe(*y_train_list.columns, y_train_list)\n",
    "#y_val = Surv.from_dataframe(*y_val.columns, y_val)\n",
    "y_test = Surv.from_dataframe(*y_test.columns, y_test)\n",
    "\n",
    "wsi_dict = {'train': [], 'val' : [], 'test': []}\n",
    "#y_train = (y_train[1],y_train[0])\n",
    "\n",
    "# Transform the data so we can use it\n",
    "pipe.fit(X_train.copy(), y_train_list.copy())\n",
    "#  X_val_c   = pipe.score(X_val.copy(), y_val)\n",
    "X_test_c   = pipe.score(X_test.copy(), y_test)\n",
    "total_c_index.append(X_test_c)\n",
    "\n",
    "X_test_t = pipe[:-1].transform(X_test)\n",
    "X_train_t = pipe[:-1].transform(X_train)\n",
    "\n",
    "y_hat   = pipe[-1].predict_survival_function(X_test_t)\n",
    "\n",
    "times   = np.arange(1,23)\n",
    "preds   = np.asarray([[fn(t) for t in times] for fn in y_hat])\n",
    "total_ib_score.append(integrated_brier_score(y_test, y_test, preds, times))\n",
    "print(f'C-Index : {np.mean(total_c_index)} +- {np.std(total_c_index)}')\n",
    "print(f'I - Brier-score : {np.mean(total_ib_score)} +- {np.std(total_ib_score)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fdb1ed2-ad63-4a47-be0e-f6e5169675d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53953808, 0.56290256, 0.57739532, 0.57739532, 0.60012259,\n",
       "       0.62869402, 0.62869402, 0.62869402, 0.62869402, 0.62869402,\n",
       "       0.62869402, 0.62869402, 0.62869402, 0.62869402, 0.62869402,\n",
       "       0.62869402, 0.62869402, 1.62869402])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First step: obtain Ho(t) from training data\n",
    "\n",
    "from sksurv.nonparametric import nelson_aalen_estimator\n",
    "times_train  = [x[1] for x in y_train_list]\n",
    "events_train = [x[0] for x in y_train_list]\n",
    "\n",
    "Ho_t_ = nelson_aalen_estimator(events_train, times_train)[1] # Unique times [0] ; CHF [1]\n",
    "Ho_t_[18:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9307a7b2-2b71-4280-807e-b42b96db698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should add this to some sort of utils on the package\n",
    "def fill_matrix(total_times, matrix, event_times):\n",
    "    gl = []\n",
    "    for time in total_times:\n",
    "        if time in event_times:\n",
    "            time_index = event_times.index(time)\n",
    "            gl.append(matrix[time_index])\n",
    "        else:\n",
    "            gl.append(gl[-1])\n",
    "    return gl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71263b9c-9c6c-4d4b-b9b0-71a08ada7573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second step: Obtain the synthetic data\n",
    "from survLime import survlime_tabular\n",
    "num_pat = 500\n",
    "\n",
    "columns = X_test_t.columns.tolist()\n",
    "explainer = survlime_tabular.LimeTabularExplainer(X_train_t, feature_names=columns, class_names=None,\n",
    "                                                   categorical_features=None, verbose=True, mode='regression', discretize_continuous=False)\n",
    "\n",
    "synthetic_data = explainer.data_inverse(X_test_t.iloc[0], num_pat) # At [0] we have the data and at [1] the inverse, see what is this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e651da1-8dae-4c2d-8ee8-6b77ccb9933d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but RandomSurvivalForest was fitted with feature names\n"
     ]
    }
   ],
   "source": [
    "# Third step: Obtain the prediction for the synthetic data \n",
    "H_i_j = pipe[-1].predict_cumulative_hazard_function(synthetic_data[1]) # X_test_t -> [371, num_features]\n",
    "times_to_fill = list(set(times_train))\n",
    "H_i_j[0]\n",
    "H_i_j_wc = [fill_matrix(times_to_fill, x.y, list(x.x)) for x in H_i_j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e71b1523-cc14-4099-b019-ada889ed99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forth step: Compute the weights\n",
    "from functools import partial\n",
    "def kernel(d, kernel_width):\n",
    "    return np.sqrt(np.exp(-(d ** 2) / kernel_width ** 2)) \n",
    "kernel_fn = partial(kernel, kernel_width=5)\n",
    "\n",
    "# We need to do the line 362 from survlime_tabular (scale the data)\n",
    "scaled_data = synthetic_data[0]\n",
    "distances = sklearn.metrics.pairwise_distances(\n",
    "            scaled_data,\n",
    "            scaled_data[0].reshape(1,-1), # <-- Point of inquiry\n",
    "            metric = 'euclidean').ravel()\n",
    "weights = kernel_fn(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dafae617-372c-471f-9924-cd0cdc8e0612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time creating the cost list 2.8493509613908827\n",
      "time summing the cost list 2.9629415972158313\n",
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.2.1                                    \n",
      "===============================================================================\n",
      "(CVXPY) Jun 27 12:13:05 PM: Your problem has 3 variables, 0 constraints, and 0 parameters.\n",
      "(CVXPY) Jun 27 12:13:07 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Jun 27 12:13:07 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Jun 27 12:13:07 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jun 27 12:13:09 PM: Compiling problem (target solver=OSQP).\n",
      "(CVXPY) Jun 27 12:13:09 PM: Reduction chain: CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> OSQP\n",
      "(CVXPY) Jun 27 12:13:09 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Jun 27 12:13:09 PM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Jun 27 12:13:16 PM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Jun 27 12:13:28 PM: Applying reduction OSQP\n",
      "(CVXPY) Jun 27 12:13:28 PM: Finished problem compilation (took 2.146e+01 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jun 27 12:13:28 PM: Invoking solver OSQP  to obtain a solution.\n",
      "-----------------------------------------------------------------\n",
      "           OSQP v0.6.2  -  Operator Splitting QP Solver\n",
      "              (c) Bartolomeo Stellato,  Goran Banjac\n",
      "        University of Oxford  -  Stanford University 2021\n",
      "-----------------------------------------------------------------\n",
      "problem:  variables n = 17003, constraints m = 17000\n",
      "          nnz(P) + nnz(A) = 84966\n",
      "settings: linear system solver = qdldl,\n",
      "          eps_abs = 1.0e-05, eps_rel = 1.0e-05,\n",
      "          eps_prim_inf = 1.0e-04, eps_dual_inf = 1.0e-04,\n",
      "          rho = 1.00e-01 (adaptive),\n",
      "          sigma = 1.00e-06, alpha = 1.60, max_iter = 10000\n",
      "          check_termination: on (interval 25),\n",
      "          scaling: on, scaled_termination: off\n",
      "          warm start: on, polish: on, time_limit: off\n",
      "\n",
      "iter   objective    pri res    dua res    rho        time\n",
      "   1   0.0000e+00   1.80e+01   5.71e+06   1.00e-01   1.00e-02s\n",
      "  50   3.3080e+04   1.98e-05   7.69e-05   4.92e-03   2.40e-02s\n",
      "plsh   3.3080e+04   3.23e-14   9.00e-11   --------   3.01e-02s\n",
      "\n",
      "status:               solved\n",
      "solution polish:      successful\n",
      "number of iterations: 50\n",
      "optimal objective:    33080.0303\n",
      "run time:             3.01e-02s\n",
      "optimal rho estimate: 3.42e-03\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jun 27 12:13:29 PM: Problem status: optimal\n",
      "(CVXPY) Jun 27 12:13:29 PM: Optimal value: 3.308e+04\n",
      "(CVXPY) Jun 27 12:13:29 PM: Compilation took 2.146e+01 seconds\n",
      "(CVXPY) Jun 27 12:13:29 PM: Solver (including time spent in interface) took 3.390e-02 seconds\n",
      "time solving the problem 24.35861592181027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.27623813,  1.10829642, -0.0129378 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "# code you want to evaluate\n",
    "timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "import cvxpy as cp\n",
    "from math import log\n",
    "epsilon = 0.00000001\n",
    "n = 3 # For now we are only using 3 features\n",
    "num_times = 34\n",
    "b = cp.Variable(n)\n",
    "\n",
    "cost = [weights[k]*cp.square((log(H_i_j_wc[k][j]+epsilon) - log(Ho_t_[j]+epsilon) - b @ scaled_data[k]))\\\n",
    "        *(times_to_fill[j+1]-times_to_fill[j]) for k in range(num_pat) for j in range(num_times)]\n",
    "#cost = [weights[k]*cp.norm((log(H_i_j_wc[k][j]+epsilon) - log(Ho_t_[j]+epsilon) - b @ scaled_data[k]),'inf') \\\n",
    "#                                            for k in range(num_pat) for j in range(num_times)]\n",
    "print(f'time creating the cost list {timeit.default_timer() - start_time}')\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "cost_sum = cp.sum(cost)\n",
    "\n",
    "print(f'time summing the cost list {timeit.default_timer() - start_time}')\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "prob = cp.Problem(cp.Minimize(cost_sum))\n",
    "\n",
    "\n",
    "opt_val = prob.solve(verbose=True)\n",
    "print(f'time solving the problem {timeit.default_timer() - start_time}')\n",
    "b.value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
